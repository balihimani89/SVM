{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from contractions import contractions_dict\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from itertools import filterfalse\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_titles(text):\n",
    "    if \"Subject: re :\" in text:\n",
    "        return text[13:]\n",
    "    elif \"Subject: news :\" in text:\n",
    "        return text[15:]\n",
    "    else:\n",
    "        return text[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: strip_titles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tokens(list_of_tokens):\n",
    "    return map(lambda x: x.lower(),list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: normalize_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contracted_word_expansion(token):\n",
    "    if token in contractions_dict.keys():\n",
    "        return contractions_dict[token]\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions_expansion(list_of_tokens):\n",
    "    return map(contracted_word_expansion,list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: contractions_expansion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'^@[a-zA-z0-9]|^#[a-zA-Z0-9]|\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*|\\W+|\\d+|<(\"[^\"]*\"|\\'[^\\']*\\'|[^\\'\">])*>|_+|[^\\u0000-\\u007f]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waste_word_or_not(token):\n",
    "    return re.search(regex,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_waste_words(list_of_tokens):\n",
    "    return filterfalse(waste_word_or_not,list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: filter_waste_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(list_of_tokens):\n",
    "    return map(lambda x: re.split(regex,x)[0],list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: split(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop_words = list(set(stopwords.words('english')).union(set(STOP_WORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stopword(token):\n",
    "    return not(token in en_stop_words or re.search(r'\\b\\w\\b|[^\\u0000-\\u007f]+|_+|\\W+',token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(list_of_tokens):\n",
    "    return filter(is_stopword,list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: stopwords_removal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wnet_pos_tag(treebank_tag):\n",
    "    if treebank_tag[1].startswith('J'):\n",
    "        return (treebank_tag[0],wordnet.ADJ)\n",
    "    elif treebank_tag[1].startswith('V'):\n",
    "        return (treebank_tag[0],wordnet.VERB)\n",
    "    elif treebank_tag[1].startswith('N'):\n",
    "        return (treebank_tag[0],wordnet.NOUN)\n",
    "    elif treebank_tag[1].startswith('R'):\n",
    "        return (treebank_tag[0],wordnet.ADV)\n",
    "    else:\n",
    "        (treebank_tag[0],wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(list_of_tokens):\n",
    "    return map(get_wnet_pos_tag,pos_tag(list_of_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: get_pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lemmatization(token_pos_tuple):\n",
    "    if token_pos_tuple == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word=token_pos_tuple[0],pos=token_pos_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(list_of_tokens):\n",
    "    if len(list_of_tokens) > 0:\n",
    "        return map(lambda x: token_lemmatization(x),list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for list_of_tokens in data['text']:\n",
    "    vocab = vocab.union(set(list_of_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = dict(zip(vocab,list(range(0,len(vocab)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens(list_of_tokens):\n",
    "    return \" \".join(list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: join_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list()\n",
    "for email_text in data['text']:\n",
    "    corpus.append(email_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=vocab_dict)\n",
    "tf_idf_matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = tf_idf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spam'] = data['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix_reduced = pca.fit_transform(tf_idf_matrix)\n",
    "tf_idf_matrix_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=tf_idf_matrix_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 101)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'] = data['spam']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:,0:100]\n",
    "y_train = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories = gnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      4360\n",
      "           1       0.72      0.82      0.77      1368\n",
      "\n",
      "    accuracy                           0.88      5728\n",
      "   macro avg       0.83      0.86      0.84      5728\n",
      "weighted avg       0.89      0.88      0.88      5728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train,y_pred=predicted_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SMO import smo_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.151228</td>\n",
       "      <td>0.178181</td>\n",
       "      <td>-0.234092</td>\n",
       "      <td>0.318191</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>-0.006338</td>\n",
       "      <td>0.109231</td>\n",
       "      <td>0.061892</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>-0.051042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.011359</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.077254</td>\n",
       "      <td>0.038657</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>-0.038706</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>-0.014736</td>\n",
       "      <td>-0.008404</td>\n",
       "      <td>-0.018160</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>0.036472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012398</td>\n",
       "      <td>-0.006673</td>\n",
       "      <td>-0.012331</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>-0.017605</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.106518</td>\n",
       "      <td>0.065937</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.012164</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.053930</td>\n",
       "      <td>-0.017528</td>\n",
       "      <td>0.054324</td>\n",
       "      <td>-0.013720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>-0.021850</td>\n",
       "      <td>-0.021478</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>-0.014650</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>0.071733</td>\n",
       "      <td>0.050520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.112580</td>\n",
       "      <td>0.050676</td>\n",
       "      <td>0.116470</td>\n",
       "      <td>0.059507</td>\n",
       "      <td>-0.054831</td>\n",
       "      <td>0.080401</td>\n",
       "      <td>-0.026957</td>\n",
       "      <td>-0.067632</td>\n",
       "      <td>-0.033101</td>\n",
       "      <td>-0.022549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.033665</td>\n",
       "      <td>-0.028658</td>\n",
       "      <td>-0.040202</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>-0.022151</td>\n",
       "      <td>-0.023867</td>\n",
       "      <td>-0.030197</td>\n",
       "      <td>-0.059284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.108220</td>\n",
       "      <td>0.084269</td>\n",
       "      <td>0.039310</td>\n",
       "      <td>-0.085947</td>\n",
       "      <td>-0.093243</td>\n",
       "      <td>-0.038087</td>\n",
       "      <td>-0.057611</td>\n",
       "      <td>0.100305</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>-0.005789</td>\n",
       "      <td>-0.030297</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>-0.012622</td>\n",
       "      <td>-0.016286</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>-0.015865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>0.401540</td>\n",
       "      <td>0.074827</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>0.019541</td>\n",
       "      <td>-0.029358</td>\n",
       "      <td>-0.015947</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027403</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.011671</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>-0.012867</td>\n",
       "      <td>-0.064943</td>\n",
       "      <td>0.077036</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>-0.025210</td>\n",
       "      <td>-0.081564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>-0.047198</td>\n",
       "      <td>-0.099707</td>\n",
       "      <td>-0.082818</td>\n",
       "      <td>-0.068373</td>\n",
       "      <td>-0.093367</td>\n",
       "      <td>0.098876</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-0.043702</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>-0.021770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059248</td>\n",
       "      <td>-0.096295</td>\n",
       "      <td>-0.051853</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.040050</td>\n",
       "      <td>0.079912</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.012607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>0.105271</td>\n",
       "      <td>-0.155611</td>\n",
       "      <td>-0.151001</td>\n",
       "      <td>-0.077213</td>\n",
       "      <td>-0.117468</td>\n",
       "      <td>0.189585</td>\n",
       "      <td>-0.039609</td>\n",
       "      <td>-0.066671</td>\n",
       "      <td>0.266276</td>\n",
       "      <td>-0.059878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068468</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>-0.040981</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>0.037558</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.057595</td>\n",
       "      <td>0.029856</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>-0.031591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>0.360915</td>\n",
       "      <td>0.106249</td>\n",
       "      <td>-0.033290</td>\n",
       "      <td>-0.053303</td>\n",
       "      <td>-0.053544</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.026760</td>\n",
       "      <td>-0.050556</td>\n",
       "      <td>-0.069254</td>\n",
       "      <td>-0.030160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041254</td>\n",
       "      <td>-0.049547</td>\n",
       "      <td>-0.060371</td>\n",
       "      <td>-0.016703</td>\n",
       "      <td>-0.054060</td>\n",
       "      <td>-0.032394</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.092943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>-0.101315</td>\n",
       "      <td>0.056496</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-0.023228</td>\n",
       "      <td>0.150196</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>-0.003757</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>-0.053019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004493</td>\n",
       "      <td>0.027851</td>\n",
       "      <td>0.041763</td>\n",
       "      <td>-0.016915</td>\n",
       "      <td>-0.005122</td>\n",
       "      <td>-0.013667</td>\n",
       "      <td>-0.042224</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.018465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.151228  0.178181 -0.234092  0.318191  0.007274 -0.006338  0.109231   \n",
       "1    -0.077254  0.038657  0.010552 -0.038706 -0.022500 -0.014736 -0.008404   \n",
       "2    -0.106518  0.065937  0.019646  0.000584 -0.012164  0.014756  0.053930   \n",
       "3    -0.112580  0.050676  0.116470  0.059507 -0.054831  0.080401 -0.026957   \n",
       "4    -0.108220  0.084269  0.039310 -0.085947 -0.093243 -0.038087 -0.057611   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5723  0.401540  0.074827  0.020231  0.019541 -0.029358 -0.015947  0.007501   \n",
       "5724 -0.047198 -0.099707 -0.082818 -0.068373 -0.093367  0.098876  0.005325   \n",
       "5725  0.105271 -0.155611 -0.151001 -0.077213 -0.117468  0.189585 -0.039609   \n",
       "5726  0.360915  0.106249 -0.033290 -0.053303 -0.053544  0.005257  0.026760   \n",
       "5727 -0.101315  0.056496  0.007457 -0.023228  0.150196  0.015921 -0.003757   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.061892  0.033337 -0.051042  ... -0.009817  0.006532  0.000633   \n",
       "1    -0.018160  0.012296  0.036472  ... -0.012398 -0.006673 -0.012331   \n",
       "2    -0.017528  0.054324 -0.013720  ... -0.016684 -0.021850 -0.021478   \n",
       "3    -0.067632 -0.033101 -0.022549  ...  0.001618  0.032069  0.033665   \n",
       "4     0.100305  0.001455  0.015863  ...  0.009377 -0.005789 -0.030297   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5723  0.004625  0.003927  0.000372  ...  0.027403 -0.019701 -0.011671   \n",
       "5724 -0.043702  0.026293 -0.021770  ... -0.059248 -0.096295 -0.051853   \n",
       "5725 -0.066671  0.266276 -0.059878  ... -0.068468  0.010795 -0.040981   \n",
       "5726 -0.050556 -0.069254 -0.030160  ... -0.041254 -0.049547 -0.060371   \n",
       "5727  0.017975  0.006364 -0.053019  ... -0.004493  0.027851  0.041763   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.000364  0.008472  0.002114  0.011359 -0.002240 -0.003400  0.000784  \n",
       "1     0.006794  0.003233 -0.017605 -0.005727  0.007719  0.004561  0.002232  \n",
       "2     0.025194  0.011361 -0.014650  0.002782  0.026294  0.071733  0.050520  \n",
       "3    -0.028658 -0.040202  0.010293 -0.022151 -0.023867 -0.030197 -0.059284  \n",
       "4    -0.000844 -0.012622 -0.016286 -0.001659  0.002003 -0.016872 -0.015865  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5723  0.008613 -0.012867 -0.064943  0.077036  0.007240 -0.025210 -0.081564  \n",
       "5724 -0.004085  0.000985  0.040050  0.079912  0.040317  0.019032  0.012607  \n",
       "5725 -0.009467  0.037558 -0.050063 -0.057595  0.029856  0.078313 -0.031591  \n",
       "5726 -0.016703 -0.054060 -0.032394 -0.021341 -0.021441  0.040905  0.092943  \n",
       "5727 -0.016915 -0.005122 -0.013667 -0.042224 -0.000974  0.002492  0.018465  \n",
       "\n",
       "[5728 rows x 100 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# If X_train is a DataFrame and y_train is a Series\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert data if needed\n",
    "X_np = X_resampled.to_numpy()\n",
    "y_np = y_resampled\n",
    "\n",
    "# Step 2: Train the model\n",
    "model = smo_algo(train_data_features=X_np, labels=y_np, reg_strength=1.0, tolerance=0.01)\n",
    "model.smo_algo_main_loop()\n",
    "\n",
    "# Step 3: Predict on training data\n",
    "train_predictions = model.predict(X_np)  # ✅ Use the predict method\n",
    "\n",
    "# Step 4: Evaluate accuracy\n",
    "accuracy = np.mean(train_predictions == y_np)\n",
    "print(\"Training accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8720, 100)\n",
      "theta_hat shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", model.X.shape)\n",
    "print(\"theta_hat shape:\", model.theta_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_hat: (100,)\n",
      "Sample 0: X[i] shape = (100,)\n",
      "Sample 1: X[i] shape = (100,)\n",
      "Sample 2: X[i] shape = (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"theta_hat:\", model.theta_hat.shape)  # should be (5000,)\n",
    "for i in range(3):\n",
    "    print(f\"Sample {i}: X[i] shape = {model.X[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.9736382681564246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Accuracy:\", clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 4360, 1: 1368}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 4360, 1: 4360}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9814220183486239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.96      0.98      4360\n",
      "           1       0.97      1.00      0.98      4360\n",
      "\n",
      "    accuracy                           0.98      8720\n",
      "   macro avg       0.98      0.98      0.98      8720\n",
      "weighted avg       0.98      0.98      0.98      8720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1.0)  # or try 'rbf' or 'poly' kernels\n",
    "clf.fit(X_np, y_np)\n",
    "y_pred = clf.predict(X_np)\n",
    "\n",
    "# Classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_np, y_pred))\n",
    "print(classification_report(y_np, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
